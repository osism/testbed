---
- name: Deploy testbed
  hosts: all

  vars_files:
    - vars/mappings.yml
    - vars/repositories.yml

  vars:
    ansible_galaxy: ~/venv/bin/ansible-galaxy
    ansible_path: "{{ basepath }}/ansible"
    ansible_playbook: ~/venv/bin/ansible-playbook
    basepath: "{{ ansible_user_dir }}/src/{{ repositories['testbed']['path'] }}"
    manager_address_file: "{{ terraform_path }}/.MANAGER_ADDRESS.{{ cloud }}"
    repo_path: "{{ ansible_user_dir }}/src/{{ repository_server }}"

    manual_create: false
    manual_deploy: false

    run_bootstrap: true
    run_checks: true

    terraform_binary: "{{ ansible_user_dir }}/terragrunt"
    terraform_path: "{{ basepath }}/terraform"

    _ceph_version: "{{ ceph_version | default('reef') }}"
    _manager_version: "{{ manager_version | default('latest') }}"
    _openstack_version: "{{ openstack_version | default('2024.2') }}"

    _nutshell: "{{ nutshell | default(false) | bool }}"
    _tempest: "{{ tempest | default(false) | bool }}"
    _prometheus_alert_status: "{{ prometheus_alert_status | default(false) | bool }}"

    _ceph_stack: "{{ ceph_stack | default('ceph-ansible') }}"

    _terraform_environment: "{{ terraform_environment | default('ci-ubuntu-22.04') }}"

  tasks:
    - name: Print used ceph version
      ansible.builtin.debug:
        var: _ceph_version

    - name: Print used openstack version
      ansible.builtin.debug:
        var: _openstack_version

    - name: Print used manager version
      ansible.builtin.debug:
        var: _manager_version

    - name: Set facts (Zuul deployment)
      ansible.builtin.set_fact:
        cloud: "{{ cloud_envs[hostvars[groups['all'][0]]['nodepool']['label']] }}"
        image_username: "{{ image_usernames[_terraform_environment] | default('ubuntu') }}"
        terragrunt_tfpath: "{{ ansible_user_dir }}/terraform"
      when: "'nodepool' in hostvars[groups['all'][0]]"

    - name: Set facts (local deployment)
      ansible.builtin.set_fact:
        cloud: "{{ testbed_cloud | default('ci') }}"
        image_username: "{{ image_usernames[_terraform_environment] | default('ubuntu') }}"
        terragrunt_tfpath: terraform
      when: "'nodepool' not in hostvars[groups['all'][0]]"

    - name: Create infrastructure (latest)
      ansible.builtin.command:
        chdir: "{{ terraform_path }}"
        cmd: |
          make
            ENVIRONMENT={{ _terraform_environment }}
            CLOUD={{ cloud }}
            IMAGE_USERNAME={{ image_username }}
            TERRAFORM={{ terraform_binary }}
            VERSION_CEPH={{ _ceph_version }}
            VERSION_MANAGER={{ _manager_version }}
            VERSION_OPENSTACK={{ _openstack_version }}
            TEMPEST={{ _tempest | lower }}
            CEPH_STACK={{ _ceph_stack }}
            create
      when:
        - not manual_create | bool
        - _manager_version == "latest"
      changed_when: true
      environment:
        TERRAGRUNT_TFPATH: "{{ terragrunt_tfpath }}"

    - name: Create infrastructure (stable)
      ansible.builtin.command:
        chdir: "{{ terraform_path }}"
        cmd: |
          make
            ENVIRONMENT={{ _terraform_environment }}
            CLOUD={{ cloud }}
            IMAGE_USERNAME={{ image_username }}
            TERRAFORM={{ terraform_binary }}
            VERSION_MANAGER={{ _manager_version }}
            TEMPEST={{ _tempest | lower }}
            CEPH_STACK={{ _ceph_stack }}
            create
      when:
        - not manual_create | bool
        - _manager_version != "latest"
      changed_when: true
      environment:
        TERRAGRUNT_TFPATH: "{{ terragrunt_tfpath }}"

    - name: Fetch manager address
      ansible.builtin.slurp:
        src: "{{ manager_address_file }}"
      register: manager_address

    - name: Set manager_host address
      ansible.builtin.set_fact:
        manager_host: "{{ manager_address['content'] | b64decode | trim | split('=') | last | replace('\"', '') }}"

    - name: Update ansible collections
      ansible.builtin.command:
        chdir: "{{ ansible_user_dir }}"
        cmd: |
          {{ ansible_galaxy }} collection install --force "{{ repo_path }}/osism/ansible-collection-{{ item }}"
      loop:
        - commons
        - services
      changed_when: true

    - name: Wait up to 300 seconds for port 22 to become open and contain "OpenSSH"
      ansible.builtin.wait_for:
        port: 22
        host: "{{ manager_host }}"
        search_regex: OpenSSH
        delay: 10
        timeout: 300

    - name: Wait a little longer for the manager so that everything is ready
      ansible.builtin.pause:
        seconds: 60

    - name: Fetch manager ssh hostkey
      ansible.builtin.shell: "ssh-keyscan {{ manager_host }} >> {{ ansible_user_dir }}/.ssh/known_hosts"
      changed_when: true
      no_log: true

    - name: Get ssh keypair from terraform environment
      ansible.builtin.shell:
        chdir: "{{ ansible_path }}"
        cmd: cp {{ terraform_path }}/.id* .
      changed_when: true

    - name: Point out that the following task takes some time and does not give any output
      ansible.builtin.debug:
        msg: "The task 'Run manager part 0' runs an Ansible playbook on the manager. There is no further output of this here. It takes a few minutes for this task to complete."

    - name: Run manager part 0
      ansible.builtin.shell:
        chdir: "{{ ansible_path }}"
        cmd: |
          set -o pipefail
          {{ ansible_playbook }} \
            -i {{ terraform_path }}/inventory.{{ cloud }} \
            --key-file {{ terraform_path }}/.id_rsa.{{ cloud }} \
            -e cloud={{ cloud }} \
            -e terraform_environment={{ _terraform_environment }} \
            -e repo_path={{ repo_path }} \
            manager-part-0.yml | tee -a ansible-manager-part-0.log
      args:
        executable: /bin/bash
      changed_when: true

    - name: Point out that the log in on the manager is now possible
      ansible.builtin.debug:
        msg: "It is now already possible to log in to the manager with 'make login'."

    - name: Point out that the following task takes some time and does not give any output
      ansible.builtin.debug:
        msg: "The task 'Run manager part 1 + 2' runs an Ansible playbook on the manager. There is no further output of this here. It takes a few minuts for this task to complete."

    - name: Run manager part 1 + 2
      ansible.builtin.shell:
        chdir: "{{ ansible_path }}"
        cmd: |
          set -o pipefail
          {{ ansible_playbook }} \
            -i {{ terraform_path }}/inventory.{{ cloud }} \
            --key-file {{ terraform_path }}/.id_rsa.{{ cloud }} \
            -e cloud={{ cloud }} \
            -e terraform_environment={{ _terraform_environment }} \
            -e repo_path={{ repo_path }} \
            -e manager_version={{ _manager_version }} \
            manager-part-1.yml | tee -a ansible-manager-part-1.log
      args:
        executable: /bin/bash
      changed_when: true

    - name: Reboot manager
      ansible.builtin.command:
        cmd: "ssh -i {{ terraform_path }}/.id_rsa.{{ cloud }} dragon@{{ manager_host }} sudo shutdown -r now"
      changed_when: true
      failed_when: false

    - name: Wait up to 300 seconds for port 22 to become open and contain "OpenSSH"
      ansible.builtin.wait_for:
        port: 22
        host: "{{ manager_host }}"
        search_regex: OpenSSH
        delay: 10
        timeout: 300

    - name: Wait a little longer for the manager so that everything is ready
      ansible.builtin.pause:
        seconds: 60

    - name: Deploy manager + bootstrap nodes
      ansible.builtin.command:
        cmd: "ssh -i {{ terraform_path }}/.id_rsa.{{ cloud }} dragon@{{ manager_host }} /opt/configuration/scripts/deploy-manager.sh"
      when: not manual_deploy | bool
      changed_when: true

    - name: Deploy services
      ansible.builtin.command:
        cmd: "ssh -i {{ terraform_path }}/.id_rsa.{{ cloud }} dragon@{{ manager_host }} /opt/configuration/scripts/deploy-services.sh"
      when:
        - not manual_deploy | bool
        - not _nutshell | bool
      changed_when: true

    - name: Deploy in a nutshell
      ansible.builtin.command:
        cmd: "ssh -i {{ terraform_path }}/.id_rsa.{{ cloud }} dragon@{{ manager_host }} /opt/configuration/scripts/deploy-in-a-nutshell.sh"
      when:
        - not manual_deploy | bool
        - _nutshell | bool
      changed_when: true

    - name: Bootstrap services
      ansible.builtin.command:
        cmd: "ssh -i {{ terraform_path }}/.id_rsa.{{ cloud }} dragon@{{ manager_host }} /opt/configuration/scripts/bootstrap.sh"
      when:
        - not manual_deploy | bool
        - run_bootstrap | bool
      changed_when: true

    - name: Run checks
      ansible.builtin.command:
        cmd: "ssh -i {{ terraform_path }}/.id_rsa.{{ cloud }} dragon@{{ manager_host }} /opt/configuration/scripts/check.sh"
      when:
        - not manual_deploy | bool
        - run_checks | bool
      changed_when: true

    - name: Run tempest
      ansible.builtin.command:
        cmd: "ssh -i {{ terraform_path }}/.id_rsa.{{ cloud }} dragon@{{ manager_host }} /opt/configuration/scripts/check/302-openstack-with-tempest.sh"
      when:
        - not manual_deploy | bool
        - _tempest | bool
      changed_when: true

    - name: Check prometheus alert status
      ansible.builtin.command:
        cmd: "ssh -i {{ terraform_path }}/.id_rsa.{{ cloud_env }} dragon@{{ manager_host }} /opt/configuration/scripts/check/303-prometheus-alert-status.sh"
      when:
        - not manual_deploy | bool
        - _prometheus_alert_status | bool
      changed_when: true
