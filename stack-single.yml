---
heat_template_version: 2018-08-31

###########
parameters:

  image:
    type: string
    constraints:
      - custom_constraint: glance.image
    default: Ubuntu 18.04

  flavor_manager:
    type: string
    constraints:
      - custom_constraint: nova.flavor
    default: 2C-4GB-20GB

  availability_zone:
    type: string
    default: south-1

  volume_az:
    type: string
    default: south-1

  public:
    type: string
    constraints:
      - custom_constraint: neutron.network
    default: public

  deploy_infrastructure:
    type: boolean
    default: false

  deploy_openstack:
    type: boolean
    default: false

  deploy_ceph:
    type: boolean
    default: false

##########
resources:

  #########
  # Generic
  #########

  key:
    type: OS::Nova::KeyPair
    properties:
      name: testbed
      save_private_key: true

  manager_wait_handle:
    type: OS::Heat::WaitConditionHandle

  manager_wait_condition:
    type: OS::Heat::WaitCondition
    properties:
      handle: {get_resource: manager_wait_handle}
      count: 1
      timeout: 7200

  manager_boot_config:
    type: OS::Heat::CloudConfig
    properties:
      cloud_config:
        package_update: true
        package_upgrade: true
        packages:
          - ifupdown
        write_files:
          - content: {get_attr: [key, public_key]}
            path: /home/ubuntu/.ssh/id_rsa.pub
            permissions: 0600
          - content: {get_attr: [key, private_key]}
            path: /home/ubuntu/.ssh/id_rsa
            permissions: 0600
          - content:
              str_replace:
                params:
                  deploy_ceph: {get_param: deploy_ceph}
                  deploy_infrastructure: {get_param: deploy_infrastructure}
                  deploy_openstack: {get_param: deploy_openstack}
                  wc_notify: {get_attr: ['manager_wait_handle', 'curl_cli']}
                template: |
                  #!/usr/bin/env bash

                  chown -R ubuntu:ubuntu /home/ubuntu/.ssh

                  add-apt-repository --yes ppa:ansible/ansible
                  apt-get install --yes ansible

                  ansible-galaxy install git+https://github.com/openstack/ansible-hardening
                  ansible-galaxy install git+https://github.com/osism/ansible-chrony
                  ansible-galaxy install git+https://github.com/osism/ansible-common
                  ansible-galaxy install git+https://github.com/osism/ansible-docker
                  ansible-galaxy install git+https://github.com/osism/ansible-operator
                  ansible-galaxy install git+https://github.com/osism/ansible-repository
                  ansible-galaxy install git+https://github.com/osism/ansible-resolvconf

                  curl https://raw.githubusercontent.com/osism/testbed/master/playbooks/node.yml > /root/node.yml
                  ansible-playbook -i localhost, /root/node.yml

                  cp /home/ubuntu/.ssh/id_rsa /home/dragon/.ssh/id_rsa
                  cp /home/ubuntu/.ssh/id_rsa.pub /home/dragon/.ssh/id_rsa.pub
                  chown -R dragon:dragon /home/dragon/.ssh

                  sudo -iu dragon ansible-galaxy install git+https://github.com/osism/ansible-configuration
                  sudo -iu dragon ansible-galaxy install git+https://github.com/osism/ansible-manager

                  curl https://raw.githubusercontent.com/osism/testbed/master/playbooks/manager-part-1.yml | sudo -iu dragon tee /home/dragon/manager-part-1.yml
                  curl https://raw.githubusercontent.com/osism/testbed/master/playbooks/manager-part-2.yml | sudo -iu dragon tee /home/dragon/manager-part-2.yml
                  sudo -iu dragon ansible-playbook -i localhost, /home/dragon/manager-part-1.yml
                  sudo -iu dragon ansible-playbook -i localhost, /home/dragon/manager-part-2.yml

                  sudo -iu dragon docker cp /home/dragon/.ssh/id_rsa.pub manager_osism-ansible_1:/share/id_rsa.pub

                  rm /home/ubuntu/.ssh/id_rsa*

                  # NOTE(berendt): sometimes ARA doesn't really get up after the bootstrap
                  sleep 15
                  sudo -iu dragon docker restart manager_ara-server_1
                  sleep 15

                  # NOTE(berendt): sudo -E does not work here because sudo -i is needed

                  sudo -iu dragon sh -c 'INTERACTIVE=false osism-run custom cronjobs'

                  # prepare all systems
                  if [[ 0 -gt 0 ]]; then
                      sudo -iu dragon sh -c 'INTERACTIVE=false osism-generic facts'
                      sudo -iu dragon sh -c 'INTERACTIVE=false osism-generic timezone'
                      sudo -iu dragon sh -c 'INTERACTIVE=false osism-generic hostname'
                      sudo -iu dragon sh -c 'INTERACTIVE=false osism-generic network'
                      sudo -iu dragon sh -c 'INTERACTIVE=false osism-generic hosts'

                      # NOTE: Restart the manager services to update the /etc/hosts file
                      sudo -iu dragon sh -c 'docker-compose -f /opt/manager/docker-compose.yml restart'

                      sudo -iu dragon sh -c 'INTERACTIVE=false osism-generic cockpit'
                      sudo -iu dragon sh -c 'INTERACTIVE=false osism-generic utilities'
                      sudo -iu dragon sh -c 'INTERACTIVE=false osism-generic grub'

                      # deploy helper services
                      sudo -iu dragon sh -c 'INTERACTIVE=false osism-infrastructure helper --tags sshconfig'
                      sudo -iu dragon sh -c 'INTERACTIVE=false osism-run custom generate-ssh-known-hosts'
                  fi

                  if [[ "deploy_infrastructure" == "True" ]]; then
                      sudo -iu dragon sh -c 'INTERACTIVE=false osism-infrastructure helper --tags phpmyadmin'
                      sudo -iu dragon sh -c 'INTERACTIVE=false osism-infrastructure helper --tags openstackclient'
                      sudo -iu dragon sh -c 'INTERACTIVE=false osism-infrastructure netdata'
                  fi

                  # deploy infrastructure services
                  if [[ "deploy_infrastructure" == "True" ]]; then
                      sudo -iu dragon sh -c 'INTERACTIVE=false osism-kolla deploy common'
                      sudo -iu dragon sh -c 'INTERACTIVE=false osism-kolla deploy openvswitch'
                      sudo -iu dragon sh -c 'INTERACTIVE=false osism-kolla deploy memcached'
                      sudo -iu dragon sh -c 'INTERACTIVE=false osism-kolla deploy redis'
                      sudo -iu dragon sh -c 'INTERACTIVE=false osism-kolla deploy haproxy'
                      sudo -iu dragon sh -c 'INTERACTIVE=false osism-kolla deploy elasticsearch'
                      sudo -iu dragon sh -c 'INTERACTIVE=false osism-kolla deploy kibana'
                      sudo -iu dragon sh -c 'INTERACTIVE=false osism-kolla deploy etcd'

                      # NOTE: workaround "Index .kibana belongs to a version of Kibana that cannot be
                      #       automatically migrated. Reset it or use the X-Pack upgrade assistant."
                      curl -X DELETE http://192.168.50.200:9200/.kibana

                      sudo -iu dragon sh -c 'INTERACTIVE=false osism-kolla deploy rabbitmq'
                      sudo -iu dragon sh -c 'INTERACTIVE=false osism-kolla deploy mariadb'
                  fi

                  # deploy ceph services
                  if [[ "deploy_ceph" == "True" ]]; then
                      sudo -iu dragon sh -c 'INTERACTIVE=false osism-ceph env-hci'
                      sudo -iu dragon sh -c 'INTERACTIVE=false osism-run custom fetch-ceph-keys'
                      sudo -iu dragon sh -c 'INTERACTIVE=false osism-infrastructure helper --tags cephclient'
                  fi

                  # deploy openstack services
                  if [[ "deploy_openstack" == "True" ]]; then
                      if [[ "deploy_infrastructure" != "True" ]]; then
                          echo "infrastructure services are necessary for the deployment of OpenStack"
                      else
                          sudo -iu dragon sh -c 'INTERACTIVE=false osism-kolla deploy keystone'
                          sudo -iu dragon sh -c 'INTERACTIVE=false osism-kolla deploy horizon'
                          sudo -iu dragon sh -c 'INTERACTIVE=false osism-kolla deploy placement'
                          sudo -iu dragon sh -c 'INTERACTIVE=false osism-kolla deploy glance'
                          sudo -iu dragon sh -c 'INTERACTIVE=false osism-kolla deploy cinder'
                          sudo -iu dragon sh -c 'INTERACTIVE=false osism-kolla deploy neutron'
                          sudo -iu dragon sh -c 'INTERACTIVE=false osism-kolla deploy nova'

                          sudo -iu dragon sh -c 'INTERACTIVE=false osism-run openstack bootstrap-basic'

                          sudo -iu dragon sh -c 'INTERACTIVE=false osism-kolla deploy heat'
                          sudo -iu dragon sh -c 'INTERACTIVE=false osism-kolla deploy gnocchi'
                          sudo -iu dragon sh -c 'INTERACTIVE=false osism-kolla deploy ceilometer'
                          sudo -iu dragon sh -c 'INTERACTIVE=false osism-kolla deploy aodh'
                          sudo -iu dragon sh -c 'INTERACTIVE=false osism-kolla deploy panko'
                          sudo -iu dragon sh -c 'INTERACTIVE=false osism-kolla deploy magnum'
                          sudo -iu dragon sh -c 'INTERACTIVE=false osism-kolla deploy barbican'
                          sudo -iu dragon sh -c 'INTERACTIVE=false osism-kolla deploy designate'

                          sudo -iu dragon sh -c 'INTERACTIVE=false osism-kolla deploy skydive'
                          sudo -iu dragon sh -c 'INTERACTIVE=false osism-generic manage-container -e container_action=stop -e container_name=skydive_agent -l skydive-agent'

                          sudo -iu dragon sh -c 'INTERACTIVE=false osism-run openstack bootstrap-additional'
                      fi
                  fi

                  wc_notify --data-binary '{"status": "SUCCESS"}'
            path: /root/run.sh
            permissions: 0700
        runcmd:
          - "echo 'network: {config: disabled}' > /etc/cloud/cloud.cfg.d/99-disable-network-config.cfg"
          - "rm -f /etc/network/interfaces.d/50-cloud-init.cfg"
          - "mv /etc/netplan/50-cloud-init.yaml /etc/netplan/50-cloud-init.yaml.unused"
          - "/root/run.sh"
        final_message: "The system is finally up, after $UPTIME seconds"

  #################
  # Security groups
  #################

  security_group_management:
    type: OS::Neutron::SecurityGroup
    properties:
      name: testbed-management
      rules:
        - remote_ip_prefix: 0.0.0.0/0
          protocol: tcp
          port_range_min: 22
          port_range_max: 22
        - remote_ip_prefix: 0.0.0.0/0
          protocol: tcp
          port_range_min: 9100
          port_range_max: 9100
        - remote_ip_prefix: 0.0.0.0/0
          protocol: icmp

  security_group_internal:
    type: OS::Neutron::SecurityGroup
    properties:
      name: testbed-internal
      rules:
        - remote_ip_prefix: 0.0.0.0/0
          protocol: 112
        - remote_ip_prefix: 0.0.0.0/0
          protocol: tcp
          port_range_min: 1
          port_range_max: 65535
        - remote_ip_prefix: 0.0.0.0/0
          protocol: udp
          port_range_min: 1
          port_range_max: 65535
        - remote_ip_prefix: 0.0.0.0/0
          protocol: icmp

  ############
  # Networks #
  ############

  net_management:
    type: OS::Neutron::Net
    properties:
      name: testbed-management

  subnet_management:
    type: OS::Neutron::Subnet
    properties:
      network: {get_resource: net_management}
      cidr: 192.168.40.0/24
      allocation_pools:
        -
          start: 192.168.40.100
          end: 192.168.40.110

  net_internal:
    type: OS::Neutron::Net
    properties:
      name: testbed-internal

  subnet_internal:
    type: OS::Neutron::Subnet
    properties:
      network: {get_resource: net_internal}
      cidr: 192.168.50.0/24
      gateway_ip: null
      enable_dhcp: false
      allocation_pools:
        -
          start: 192.168.50.100
          end: 192.168.50.110

  ##########################
  # Network infrastructure #
  ##########################

  router:
    type: OS::Neutron::Router
    properties:
      external_gateway_info:
        network: {get_param: public}

  router_interface:
    type: OS::Neutron::RouterInterface
    properties:
      router: {get_resource: router}
      subnet: {get_resource: subnet_management}

  ###########
  # Manager #
  ###########

  manager_floating_ip:
    type: OS::Neutron::FloatingIP
    depends_on: router_interface
    properties:
      floating_network_id: {get_param: public}
      port_id: {get_resource: manager_port_management}

  manager_port_management:
    type: OS::Neutron::Port
    properties:
      network_id: {get_resource: net_management}
      fixed_ips:
        - ip_address: 192.168.40.5
      security_groups:
        - {get_resource: security_group_management}

  manager_port_internal:
    type: OS::Neutron::Port
    properties:
      network_id: {get_resource: net_internal}
      fixed_ips:
        - ip_address: 192.168.50.5
      security_groups:
        - {get_resource: security_group_internal}

  manager_server:
    type: OS::Nova::Server
    properties:
      name: testbed-manager
      key_name: {get_resource: key}
      image: {get_param: image}
      flavor: {get_param: flavor_manager}
      availability_zone: {get_param: availability_zone}
      user_data_format: SOFTWARE_CONFIG
      user_data: {get_resource: manager_boot_config}
      metadata:
        group: manager
      config_drive: true
      networks:
        - port: {get_resource: manager_port_management}
        - port: {get_resource: manager_port_internal}
  #########
  # Nodes #
  #########


########
outputs:

  manager_address:
    value: {get_attr: [manager_floating_ip, floating_ip_address]}

  manager_address_management:
    value: {get_attr: [manager_port_management, fixed_ips, 0, ip_address]}

  manager_address_internal:
    value: {get_attr: [manager_port_internal, fixed_ips, 0, ip_address]}

  public_key:
    value: {get_attr: [key, public_key]}

  private_key:
    value: {get_attr: [key, private_key]}
